{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate CV accuracies for different RF and SVM_PUFK models, and choose the best model for AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random\n",
    "from numpy import vstack, hstack\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, Matern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, GaussianProcessRegressor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, GridSearchCV\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import entropy_sampling, entropy_sampling, margin_sampling\n",
    "from modAL.batch import uncertainty_batch_sampling\n",
    "from modAL.uncertainty import classifier_uncertainty, classifier_margin, classifier_entropy\n",
    "from modAL.utils.selection import multi_argmax\n",
    "from Models import models, plot, sampling\n",
    "from Data.datasets import save_obj, load_obj, data_preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input initial 48 experiment\n",
    "df = load_obj('8 reagent concentration_initial sampling_standardized')\n",
    "df = df.rename(columns={'Pb': 'Pb_std', \"morph\": \"morph_std\", 'DMSO': 'DMSO_std', 'GBL': 'GBL_std', 'FAH': 'FAH_std', 'H2O': 'H2O_std'})\n",
    "df_score = pd.read_csv('Data/initial sampling_score.csv')\n",
    "df_score.index = list(df_score['Index'])\n",
    "df_score = df_score.drop(['Index'], axis = 1)\n",
    "print('The index of score table matches the index of feature table?', (df.index == df_score.index).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation options\n",
    "X = df.copy()\n",
    "y = df_score.copy()\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to Random Forest model and use grid search to find best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap = [True, False]\n",
    "max_features = ['auto', 'sqrt']\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [2, 5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "\n",
    "param_grid_RFC =dict(bootstrap=bootstrap,\n",
    "                max_features=max_features,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RFC = GridSearchCV(RandomForestClassifier(criterion='entropy', class_weight = 'balanced', random_state = 42),\\\n",
    "                    param_grid=param_grid_RFC,cv=cv,n_jobs = -1)\n",
    "grid_RFC.fit(X,y)\n",
    "print(\"Best hyperparameters: \", grid_RFC.best_params_)\n",
    "print(\"Test accuracy from grid search is\", grid_RFC.best_score_)\n",
    "save_obj(grid_RFC, 'RandomForestClassifier_gridcv')\n",
    "\n",
    "RFC = grid_RFC.best_estimator_\n",
    "save_obj(RFC, 'RandomForestClassifier_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test,RFC.predict(X_test)))\n",
    "print(\"Test accuracy is\", RFC.score(X_test, y_test))\n",
    "print(\"Test accuracy from grid search is\", grid_RFC.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(RFC, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to SVM PUFK model and use grid search to find best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from Models.models import PearsonVII_kernel\n",
    "\n",
    "C_range = np.logspace(-3, 3, 7)\n",
    "param_grid_SVM = dict(C=C_range)\n",
    "    \n",
    "grid_SVM = GridSearchCV(SVC(cache_size=6000, kernel = PearsonVII_kernel, \\\n",
    "                            decision_function_shape='ovr', probability=True, class_weight='balanced'),\\\n",
    "                        param_grid=param_grid_SVM,cv=cv)\n",
    "\n",
    "grid_SVM.fit(X,np.array(y).ravel())\n",
    "print(\"Best hyperparameters: \", grid_SVM.best_params_)\n",
    "print(\"Test accuracy from grid search is\", grid_SVM.best_score_)\n",
    "save_obj(grid_SVM, 'SVM_gridcv')\n",
    "SVM = grid_SVM.best_estimator_\n",
    "save_obj(SVM, 'SVM_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test, SVM.predict(X_test)))\n",
    "print(\"Test accuracy is\", SVM.score(X_test, y_test))\n",
    "print(\"Test accuracy from grid search is\", grid_SVM.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_obj('SVM_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: Random Forest is better. So I will choose Random Forest for active learning\n",
    "#### Other reasons: 1. RF is better for multi-class classification. 2. less prone to over fitting. \n",
    "#### 3. give prediction uncertainty intrinsically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After 5th AL, a question rises that Random Forest may not be the best model for active learning or for this dataset. So I am comming back here to generate some other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to SVM RBF model and use grid search to find best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-3, 3, 7)\n",
    "gamma_range = np.logspace(-3, 3, 7)\n",
    "param_grid_SVM_rbf = dict(C = C_range, gamma = gamma_range)\n",
    "    \n",
    "grid_SVM_rbf = GridSearchCV(SVC(cache_size=6000, kernel = 'rbf', \\\n",
    "                                decision_function_shape='ovr', probability=True, class_weight='balanced'),\\\n",
    "                            param_grid=param_grid_SVM_rbf,cv=cv)\n",
    "\n",
    "grid_SVM_rbf.fit(X,np.array(y).ravel())\n",
    "print(\"Best hyperparameters: \", grid_SVM_rbf.best_params_)\n",
    "print(\"Test accuracy from grid search is\", grid_SVM_rbf.best_score_)\n",
    "save_obj(grid_SVM_rbf, 'SVM_rbf_gridcv')\n",
    "SVM_rbf = grid_SVM_rbf.best_estimator_\n",
    "save_obj(SVM_rbf, 'SVM_rbf_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_rbf.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test, SVM_rbf.predict(X_test)))\n",
    "print(\"Test accuracy is\", SVM_rbf.score(X_test, y_test))\n",
    "print(\"Test accuracy from grid search is\", grid_SVM_rbf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to xgboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xboost = xgb.XGBClassifier(base_score=0.5, booster='gbtree', n_estimators=100)\n",
    "save_obj(xboost, 'xgboost_best')\n",
    "\n",
    "xboost.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test, xboost.predict(X_test)))\n",
    "print(\"Test accuracy is\", xboost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_obj('xgboost_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to GaussianProcessClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "GPC = GaussianProcessClassifier(1.0*RBF(1.0))\n",
    "save_obj(GPC, 'GPC_best')\n",
    "\n",
    "GPC.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test, GPC.predict(X_test)))\n",
    "print(\"Test accuracy is\", GPC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_obj('GPC_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data to KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN = KNeighborsClassifier(n_neighbors = 1, weights = \"distance\", p = 2)\n",
    "save_obj(kNN, 'kNN_best')\n",
    "\n",
    "kNN.fit(X_train,y_train)\n",
    "print(\"Metric Report\")\n",
    "print(classification_report(y_test, kNN.predict(X_test)))\n",
    "print(\"Test accuracy is\", kNN.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_obj('kNN_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another GaussianProcessClassifier (popular, for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, Matern\n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=1.0, nu=2.5)\n",
    "GPC = GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer = 10)\n",
    "save_obj(GPC, 'GPC_matern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
